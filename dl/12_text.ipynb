{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_11a import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SplitData():\n",
    "    def __init__(self, train, valid):\n",
    "        self.train, self.valid = train, valid\n",
    "\n",
    "    def __getattr__(self, k):\n",
    "        return getattr(self.train, k)\n",
    "    \n",
    "    #This is needed if we want to pickle SplitData and be able to load it back without recursion errors\n",
    "    def __setstate__(self,data:Any):\n",
    "        self.__dict__.update(data)\n",
    "\n",
    "    @classmethod\n",
    "    def split_by_func(cls, il, f):\n",
    "        lists = map(il.new, split_by_func(il, f)) # il or il.items (il.items in github nb_08.py)\n",
    "        return cls(*lists)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}\\nTrain: {self.train}\\nValid: {self.valid}\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _label_by_func(ds, f, cls=ItemList):\n",
    "    return cls([f(o) for o in ds.items], path=ds.path)\n",
    "\n",
    "class LabeledData():\n",
    "    def process(self, il, proc): return il.new(compose(il.items, proc))\n",
    "\n",
    "    def __init__(self, x, y, proc_x=None, proc_y=None):\n",
    "        self.x,self.y = self.process(x, proc_x),self.process(y, proc_y)\n",
    "        self.proc_x,self.proc_y = proc_x,proc_y\n",
    "\n",
    "    def __repr__(self): return f'{self.__class__.__name__}\\nx: {self.x}\\ny: {self.y}\\n'\n",
    "    def __getitem__(self,idx): return self.x[idx],self.y[idx]\n",
    "    def __len__(self): return len(self.x)\n",
    "\n",
    "    def x_obj(self, idx): return self.obj(self.x, idx, self.proc_x)\n",
    "    def y_obj(self, idx): return self.obj(self.y, idx, self.proc_y)\n",
    "\n",
    "    def obj(self, items, idx, procs):\n",
    "        isint = isinstance(idx, int) or (isinstance(idx,torch.LongTensor) and not idx.ndim)\n",
    "        item = items[idx]\n",
    "        for proc in reversed(listify(procs)):\n",
    "            item = proc.deproc1(item) if isint else proc.deprocess(item)\n",
    "        return item\n",
    "\n",
    "    @classmethod\n",
    "    def label_by_func(cls, il, f, proc_x=None, proc_y=None):\n",
    "        return cls(il, _label_by_func(il, f), proc_x=proc_x, proc_y=proc_y)\n",
    "    \n",
    "def label_by_func(sd, f, proc_x=None, proc_y=None):\n",
    "    train = LabeledData.label_by_func(sd.train, f, proc_x=proc_x, proc_y=proc_y)\n",
    "    valid = LabeledData.label_by_func(sd.valid, f, proc_x=proc_x, proc_y=proc_y)\n",
    "    return SplitData(train,valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "imdb_path = 'https://s3.amazonaws.com/fast-ai-nlp/imdb'\n",
    "path = untar_data(imdb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ubuntu/learnai/dl/data/imdb/README'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/ll_clas.pkl'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/test'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/train'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/vocab_lm.pkl'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/ll_lm.pkl'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/ubuntu/learnai/dl/data/imdb/ld.pkl')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_file(fn):\n",
    "    with open(fn, 'r', encoding='utf8') as f:\n",
    "        return f.read()\n",
    "    \n",
    "class TextList(ItemList):\n",
    "    @classmethod\n",
    "    def from_files(cls, path, extensions='.txt', recurse=True, include=None, **kwargs):\n",
    "        return cls(get_files(path, extensions, recurse=recurse, include=include), path, **kwargs)\n",
    "    \n",
    "    def get(self, i):\n",
    "        if isinstance(i, Path):\n",
    "            return read_file(i)\n",
    "        return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "il = TextList.from_files(path, include=['train', 'test', 'unsup'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(il.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextList(100000 items)\n",
       "[PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/10274_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/5668_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/8620_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/19150_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/37632_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/21939_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/20835_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/14011_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/20552_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/33059_0.txt')...]\n",
       "Path: /home/ubuntu/learnai/dl/data/imdb"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "il"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well, this a very good TV series from our neighbor country Turkey. Its a series about romance and love.Very good indeed.Here in Greece we had a similar series but is was a dramatic one (cant understand why Greek writers are stuck on this kind...drama is not always good).To be exact I prefer the Turkish one cause combines lots of good things (characters, script etc) and cause as a curious Greek I'd love to see the Turkish point of view...with this one u can see the common cultural background of modern Greece and Turkey.This TV series was really a good surprise for me.I am addicted neighbors!!!Not forget to mention than Nehri Erdogan is the most beautiful creature on Earth!!I would be happy to see her coming here to Greece!Congratulations!!!Merhaba!\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = il[0]\n",
    "txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "??split_by_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd = SplitData.split_by_func(il, partial(random_splitter, p_valid=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SplitData\n",
       "Train: TextList(89907 items)\n",
       "[PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/10274_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/5668_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/8620_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/19150_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/37632_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/21939_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/14011_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/20552_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/33059_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/25229_0.txt')...]\n",
       "Path: /home/ubuntu/learnai/dl/data/imdb\n",
       "Valid: TextList(10093 items)\n",
       "[PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/20835_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/13943_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/25108_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/15056_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/8145_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/9373_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/42821_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/38588_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/44640_0.txt'), PosixPath('/home/ubuntu/learnai/dl/data/imdb/unsup/49725_0.txt')...]\n",
       "Path: /home/ubuntu/learnai/dl/data/imdb"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import spacy, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#special tokens\n",
    "\n",
    "UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ = 'xxunk xxpad xxbos xxeos xxrep xxwrep xxup xxmaj'.split()\n",
    "\n",
    "def sub_br(t):\n",
    "    re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
    "    return re_br.sub('\\n', t)\n",
    "\n",
    "def spec_add_spaces(t):\n",
    "    \"Add spaces around / and #\"\n",
    "    return re.sub(r'([/#])', r' \\1', t)\n",
    "\n",
    "def rm_useless_spaces(t):\n",
    "    \"Remove multiple spaces\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def replace_rep(t):\n",
    "    def _replace_rep(m):\n",
    "        c, cc = m.groups()\n",
    "        return f' {TK_REP} {len(cc)+1} {c} '\n",
    "    re_rep = re.compile(r'(\\S)(\\1{3,})')\n",
    "    return re_rep.sub(_replace_rep, t)\n",
    "\n",
    "def replace_wrep(t):\n",
    "    \"Replace word repetitions: word word word -> TK_WREP 3 word\"\n",
    "    def _replace_wrep(m):\n",
    "        c, cc = m.groups()\n",
    "        return f' {TK_WREP} {len(cc.split())+1} {c} '\n",
    "    re_wrep = re.compile(r'(\\b\\w+\\W+)(\\1{3,})')\n",
    "    return re_wrep.sub(_replace_wrep, t)\n",
    "\n",
    "def fixup_text(x):\n",
    "    \"Remove messy things\"\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;',\"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n',\"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', '\\n').replace('\\\\\"', '\"').replace('<unk>', UNK).replace(' @.@ ', '.').replace(\n",
    "        ' @-@ ', '-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "default_pre_rules = [fixup_text, replace_rep, replace_wrep, spec_add_spaces, rm_useless_spaces, sub_br]\n",
    "default_spec_tok = [UNK, PAD, BOS, EOS, TK_REP, TK_WREP, TK_UP, TK_MAJ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxrep 4 c '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_rep('cccc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' xxwrep 5 word  '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_wrep('word word word word word ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def replace_all_caps(x):\n",
    "    \"Replace tokens in ALL CAPS by their lower version and add `TK_UP` before.\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t.isupper() and len(t)>1:\n",
    "            res.append(TK_UP)\n",
    "            res.append(t.lower())\n",
    "        else:\n",
    "            res.append(t)\n",
    "    return res\n",
    "\n",
    "def deal_caps(x):\n",
    "    \"Replace all Capitalized tokens by their lower version and add `TK_MAJ` before.\"\n",
    "    res = []\n",
    "    for t in x:\n",
    "        if t == '':\n",
    "            continue\n",
    "        if t[0].isupper() and len(t)>1 and t[1:].islower():\n",
    "            res.append(TK_MAJ)\n",
    "        res.append(t.lower())\n",
    "    return res\n",
    "\n",
    "def add_eos_bos(x):\n",
    "    return [BOS] + x + [EOS]\n",
    "\n",
    "default_post_rules = [deal_caps, replace_all_caps, add_eos_bos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'xxup', 'am', 'xxup', 'shouting']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace_all_caps('I AM SHOUTING'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxmaj', 'my', 'name', 'is', 'xxmaj', 'akhil']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deal_caps('My name is Akhil'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from spacy.symbols import ORTH\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def parallel(func, arr, max_workers=4):\n",
    "    if max_workers<2:\n",
    "        results = list(progress_bar(map(func, enumerate(arr)), total=len(arr)))\n",
    "    else:\n",
    "        with ProcessPoolExecutor(max_workers=max_workers) as ex:\n",
    "            return list(progress_bar(ex.map(func, enumerate(arr)), total=len(arr)))\n",
    "    if any([o is not None for o in results]):\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [2/2 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[2, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parallel(len, ['hello', 'world'], 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "??compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TokenizeProcessor(Processor):\n",
    "    def __init__(self, lang='en', chunksize=2000, pre_rules=None, post_rules=None, max_workers=4):\n",
    "        self.chunksize, self.max_workers = chunksize, max_workers\n",
    "        self.tokenizer = spacy.blank(lang).tokenizer\n",
    "        for w in default_spec_tok:\n",
    "            self.tokenizer.add_special_case(w, [{ORTH: w}])\n",
    "        if pre_rules is None:\n",
    "            self.pre_rules = default_pre_rules\n",
    "        else:\n",
    "            self.pre_rules = pre_rules\n",
    "        if post_rules is None:\n",
    "            self.post_rules = default_post_rules\n",
    "        else:\n",
    "            self.post_rules = post_rules\n",
    "    \n",
    "    def proc_chunk(self, args):\n",
    "        i, chunk = args\n",
    "        chunk = [compose(t, self.pre_rules) for t in chunk]\n",
    "        docs = [[d.text for d in doc] for doc in self.tokenizer.pipe(chunk)]\n",
    "        docs = [compose(t, self.post_rules) for t in docs]\n",
    "        return docs\n",
    "    \n",
    "    def __call__(self, items):\n",
    "        toks = []\n",
    "        if isinstance(items[0], Path):\n",
    "            items = [read_file(i) for i in items]\n",
    "        chunks = [items[i: i+self.chunksize] for i in (range(0, len(items), self.chunksize))]\n",
    "        toks = parallel(self.proc_chunk, chunks, max_workers=self.max_workers)\n",
    "        return sum(toks, [])\n",
    "    \n",
    "    def proc1(self, item):\n",
    "        return self.proc_chunk([toks])[0]\n",
    "    \n",
    "    def deprocess(self, toks):\n",
    "        return [self.deproc1(tok) for tok in toks]\n",
    "    \n",
    "    def deproc1(self, tok):\n",
    "        return ' '.join(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TokenizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, this a very good TV series from our neighbor country Turkey. Its a series about romance and love.Very good indeed.Here in Greece we had a similar series but is was a dramatic one (cant understand why Greek writers are stuck on this kind...drama'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt[:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'xxbos • xxmaj • well • , • this • a • very • good • tv • series • from • our • neighbor • country • xxmaj • turkey • . • xxmaj • its • a • series • about • romance • and • love • . • xxmaj • very • good • indeed • . • xxmaj • here • in • xxmaj • greece • we • had • a • similar • series • but • is • was • a • dramatic • one • ( • ca • nt • understand • why • xxmaj • greek • writers • are • stuck • on • this • kind • ... • drama • is • not • always • good).to • be • exact • i • prefer • the • xxma'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' • '.join(tp(il[:100])[0])[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[['xxbos', 'hello', 'world', 'xxrep', '4', '.', 'xxeos']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp(['hello world ....'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import collections\n",
    "\n",
    "class NumericalizeProcessor(Processor):\n",
    "    def __init__(self, vocab=None, max_vocab=60000, min_freq=2):\n",
    "        self.vocab, self.max_vocab, self.min_freq = vocab, max_vocab, min_freq\n",
    "        \n",
    "    def __call__(self, items):\n",
    "        # vocab gets defined on first use\n",
    "        if self.vocab is None:\n",
    "            freq = Counter(p for o in items for p in o)\n",
    "            self.vocab = [o for o,c in freq.most_common(self.max_vocab) if c>=self.min_freq]\n",
    "            for o in reversed(default_spec_tok):\n",
    "                if o in self.vocab:\n",
    "                    self.vocab.remove(o)\n",
    "                self.vocab.insert(0, o)\n",
    "        if getattr(self, 'otoi', None) is None:\n",
    "            self.otoi = collections.defaultdict(int, {v:k for k,v in enumerate(self.vocab)})\n",
    "        return [self.proc1(o) for o in items]\n",
    "    \n",
    "    def proc1(self, item):\n",
    "        return [self.otoi[o] for o in item]\n",
    "    \n",
    "    def deprocess(self, idxs):\n",
    "        assert self.vocab is not None\n",
    "        return [self.deproc1(idx) for idx in idxs]\n",
    "    \n",
    "    def deproc1(self, idx):\n",
    "        return [self.vocab[i] for i in idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_tok, proc_num = TokenizeProcessor(max_workers=8), NumericalizeProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='45' class='' max='45', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [45/45 01:44<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='6' class='' max='6', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [6/6 00:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 2.62 s, total: 24.6 s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%time ll = label_by_func(sd, lambda x:0, proc_x = [proc_tok, proc_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"xxbos xxmaj well , this a very good tv series from our neighbor country xxmaj turkey . xxmaj its a series about romance and love . xxmaj very good indeed . xxmaj here in xxmaj greece we had a similar series but is was a dramatic one ( ca nt understand why xxmaj greek writers are stuck on this kind ... drama is not always xxunk be exact i prefer the xxmaj turkish one cause combines lots of good things ( characters , script etc ) and cause as a curious xxmaj greek i 'd love to see the xxmaj turkish point of view ... with this one u can see the common cultural background of modern xxmaj greece and xxmaj turkey . xxmaj this tv series was really a good surprise for me . i am addicted xxunk forget to mention than xxmaj xxunk xxmaj xxunk is the most beautiful creature on xxunk would be happy to see her coming here to xxunk ! xxeos\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll.train.x_obj(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ll, open(path/'ld.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/'ld.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = \"\"\"\n",
    "In this notebook, we will go back over the example of classifying movie reviews we studied in part 1 and dig deeper under the surface. \n",
    "First we will look at the processing steps necessary to convert text into numbers and how to customize it. By doing this, we'll have another example of the Processor used in the data block API.\n",
    "Then we will study how we build a language model and train it.\\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1/1 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = np.array(tp([stream])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)//bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "      <td>notebook</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>classifying</td>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "      <td>in</td>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>processor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "      <td>block</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs, seq_len = 6, len(tokens)//bs\n",
    "d_tokens = np.array([tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
    "df = pd.DataFrame(d_tokens)\n",
    "display(HTML(df.to_html(index=False, header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>in</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>classifying</td>\n",
       "      <td>movie</td>\n",
       "      <td>reviews</td>\n",
       "      <td>we</td>\n",
       "      <td>studied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>first</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>numbers</td>\n",
       "      <td>and</td>\n",
       "      <td>how</td>\n",
       "      <td>to</td>\n",
       "      <td>customize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>another</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>then</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>study</td>\n",
       "      <td>how</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>notebook</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>will</td>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>in</td>\n",
       "      <td>part</td>\n",
       "      <td>1</td>\n",
       "      <td>and</td>\n",
       "      <td>dig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>look</td>\n",
       "      <td>at</td>\n",
       "      <td>the</td>\n",
       "      <td>processing</td>\n",
       "      <td>steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>xxmaj</td>\n",
       "      <td>by</td>\n",
       "      <td>doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>processor</td>\n",
       "      <td>used</td>\n",
       "      <td>in</td>\n",
       "      <td>the</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>we</td>\n",
       "      <td>build</td>\n",
       "      <td>a</td>\n",
       "      <td>language</td>\n",
       "      <td>model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>back</td>\n",
       "      <td>over</td>\n",
       "      <td>the</td>\n",
       "      <td>example</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>deeper</td>\n",
       "      <td>under</td>\n",
       "      <td>the</td>\n",
       "      <td>surface</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>necessary</td>\n",
       "      <td>to</td>\n",
       "      <td>convert</td>\n",
       "      <td>text</td>\n",
       "      <td>into</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>this</td>\n",
       "      <td>,</td>\n",
       "      <td>we</td>\n",
       "      <td>'ll</td>\n",
       "      <td>have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>block</td>\n",
       "      <td>api</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n</td>\n",
       "      <td>xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>and</td>\n",
       "      <td>train</td>\n",
       "      <td>it</td>\n",
       "      <td>.</td>\n",
       "      <td>\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bs, bptt = 6,5\n",
    "for k in range(len(tokens)//(bs*bptt)):\n",
    "    d_tokens = np.array([tokens[i*seq_len + k*bptt:i*seq_len + (k+1)*bptt] for i in range(bs)])\n",
    "    df = pd.DataFrame(d_tokens)\n",
    "    display(HTML(df.to_html(index=False, header=None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LM_Dataset():\n",
    "    def __init__(self, data, bs=64, bptt=70, shuffle=False):\n",
    "        self.data, self.bs, self.bptt, self.shuffle = data, bs, bptt, shuffle\n",
    "        total_len = sum([len(t) for t in data.x])\n",
    "        self.n_batch = total_len // bs\n",
    "        self.batchify()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return ((self.n_batch-1) // self.bptt) * self.bs\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        source = self.batched_data[idx % self.bs]\n",
    "        seq_idx = (idx // self.bs) * self.bptt\n",
    "        return source[seq_idx:seq_idx+self.bptt], source[seq_idx+1:seq_idx+self.bptt+1]\n",
    "    \n",
    "    def batchify(self):\n",
    "        texts = self.data.x\n",
    "        if self.shuffle:\n",
    "            texts = texts[torch.randperm(len(texts))]\n",
    "        stream = torch.cat([tensor(t) for t in texts])\n",
    "        self.batched_data = stream[:self.n_batch * self.bs].view(self.bs, self.n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(LM_Dataset(ll.valid, shuffle=True), batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(dl)\n",
    "x1, y1 = next(iter_dl)\n",
    "x2, y2 = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 70]), torch.Size([64, 70]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.size(), y1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,    16,    25,  ...,    45,   272,   101],\n",
       "        [ 2772,     9,    24,  ...,   133,    42,   173],\n",
       "        [10223,    17,  2425,  ...,   532,  4508,    17],\n",
       "        ...,\n",
       "        [   21,     7,     8,  ...,    10,  8359,    27],\n",
       "        [  153,  6241,    43,  ...,     8, 23599,   142],\n",
       "        [   30,   264,    11,  ...,     7,    68,    71]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   16,    25,    19,  ...,   272,   101,    11],\n",
       "        [    9,    24,    18,  ...,    42,   173,     9],\n",
       "        [   17,  2425,    75,  ...,  4508,    17,     8],\n",
       "        ...,\n",
       "        [    7,     8,     7,  ...,  8359,    27,  6812],\n",
       "        [ 6241,    43,  5855,  ..., 23599,   142,     7],\n",
       "        [  264,    11,  3107,  ...,    68,    71,  2511]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   11,   323,    10,  ...,    11,  5298, 21672],\n",
       "        [    9,     7,     8,  ...,    10,  4258,    14],\n",
       "        [    8,   337, 52433,  ...,    19,    29,    25],\n",
       "        ...,\n",
       "        [ 6812,   121,    11,  ...,   164,    13,   200],\n",
       "        [    7,  1736,     7,  ..., 11449,    13,     7],\n",
       "        [ 2511,    57,  1359,  ...,    60,    13,   402]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = proc_num.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xxbos it was this movie , not the sixth sense , that turned me into the huge m. night shyamalan fan i am today . i saw this movie back before i even heard of the sixth sense . i saw it because i saw a trailer for it before another movie i had rented . after viewing just the trailer , my sister and i looked at each other'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(vocab[o] for o in x1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it was this movie , not the sixth sense , that turned me into the huge m. night shyamalan fan i am today . i saw this movie back before i even heard of the sixth sense . i saw it because i saw a trailer for it before another movie i had rented . after viewing just the trailer , my sister and i looked at each other and'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(vocab[o] for o in y1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and said , \" we have to see that ... \" so , when i found it at blockbuster a few months later , i jumped to rent it . now i only wish that i had gotten a chance to see this limited release movie in theaters . the story of young xxmaj joshua questioning life while everyone , including his best friend , parents , and teachers scoff'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(vocab[o] for o in x2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_lm_dls(train_ds, valid_ds, bs, bptt, **kwargs):\n",
    "    return (DataLoader(LM_Dataset(train_ds, bs, bptt, shuffle=True), batch_size=bs, **kwargs),\n",
    "           DataLoader(LM_Dataset(valid_ds, bs, bptt, shuffle=False), batch_size=2*bs, **kwargs))\n",
    "\n",
    "def lm_databunchify(sd, bs, bptt, **kwargs):\n",
    "    return DataBunch(*get_lm_dls(sd.train, sd.valid, bs, bptt, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, bptt = 64, 70\n",
    "data = lm_databunchify(ll, bs, bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batching for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_cat = CategoryProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='13' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [13/13 00:30<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='13' class='' max='13', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [13/13 00:29<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "il = TextList.from_files(path, include=['train', 'test'])\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='test'))\n",
    "ll = label_by_func(sd, parent_labeler, proc_x = [proc_tok, proc_num], proc_y=proc_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(ll, open(path/'ll_clas.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = pickle.load(open(path/'ll_clas.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"xxbos xxmaj deanna xxmaj durbin , then 14 and just under contract to mgm , made a short feature in 1936 which paired her with xxmaj judy xxmaj garland , a year younger , in the first film for both of them . xxmaj louis b. xxmaj mayer then decided he did n't need two competing young singers , placed his bet on xxmaj garland and let xxmaj durbin go . xxmaj universal immediately signed xxmaj durbin , rushed her into xxmaj three xxmaj smart xxmaj girls and rewrote the screenplay to pump up her part . xxmaj she 's billed last , but with the xxunk equivalent of neon lights around her name . xxmaj universal was convinced xxmaj durbin would be a smash , and they were right . xxmaj three xxmaj smart xxmaj girls is less a musical and more a screwball comedy , and xxmaj durbin , 15 when the movie was released , carries it with aplomb . xxmaj she 's xxmaj penny xxmaj craig , and she and her older sisters , xxmaj joan and xxmaj kay , are determined to save their father , who had divorced their mother , from the clutches of an elegant gold digger with a fierce mother . xxmaj they talk their way from xxmaj switzerland , where they live , to xxmaj new xxmaj york xxmaj city , where their father lives . xxmaj they plan not just to break up their father 's wedding but to reunite their father with their mother , who after ten years apart still loves the guy . xxmaj is there any doubt that xxmaj durbin will sing a song or two in her warm , luscious soprano ? xxmaj nope . xxmaj is there any doubt the girls will succeed ... with xxmaj kay and xxmaj joan finding love and matrimonial material along the way ? xxmaj nope , again . xxmaj years later xxmaj durbin was quoted as saying that she could n't keep playing little xxmaj miss xxmaj fixit forever . xxmaj she was right , of course , but in xxmaj three xxmaj smart xxmaj girls , her first feature movie , she has little xxmaj miss xxmaj fixit down pat . xxmaj durbin is funny , determined , resourceful , energetic and , of all things , natural . xxmaj her personality is so genuine that it makes this comedy -- a mix of farce , confusion , good intentions and cheerful avarice -- downright endearing . \\n\\n xxmaj durbin carries the movie with ease . xxmaj it 's a lot of fun watching her hold her own against the likes of xxmaj binnie xxmaj barnes as xxmaj donna xxmaj lyon , the woman with her hooks in xxmaj penny 's rich father , played by xxmaj charles xxmaj winninger , who was no slouch at stealing scenes , either . xxmaj alice xxmaj brady , who played the dithering matron in xxmaj my xxmaj man xxmaj godfrey , plays xxmaj donna xxmaj lyons ' mother , who is even more of a gold digger than her daughter . xxmaj the last of the accomplished farceurs is xxmaj ray xxmaj milland as xxmaj lord xxmaj michael xxmaj stuart , who through a contrived and amusing mix - up is mistaken for xxmaj mischa xxmaj auer . \\n\\n xxmaj three xxmaj smart xxmaj girls holds up well as a light - weight and amusing comedy of manners and xxunk ups . xxmaj so does xxmaj deanna xxmaj durbin as a brand - new star , who with her huge success saved xxmaj universal 's bacon . xxeos\",\n",
       "  'pos'),\n",
       " (\"xxbos xxmaj it could have been a morbidly fascinating look at the life of one of xxmaj america 's most notorious serial killers , but sadly it does n't even come close . xxmaj terrible editing , direction , bad acting , you name it . xxmaj this movie is literally about 10 minutes of plot stretched into 100 . xxmaj the only redeeming quality is xxmaj bruce xxmaj davidson as the father , but that 's not nearly enough to save this stinker . a 1 out of 10 . xxeos\",\n",
       "  'neg')]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(ll.train.x_obj(i), ll.train.y_obj(i)) for i in [1, 12552]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class SortSampler(Sampler):\n",
    "    def __init__(self, data_source, key):\n",
    "        self.data_source, self.key = data_source, key\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_source)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(sorted(list(range(len(self.data_source))), key=self.key, reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SortishSampler(Sampler):\n",
    "    def __init__(self, data_source, key, bs):\n",
    "        self.data_source, self.key, self.bs = data_source, key, bs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_source)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        idxs = torch.randperm(len(self.data_source))\n",
    "        megabatches = [idxs[i:i+self.bs*50] for i in range(0, len(idxs), self.bs*50)]\n",
    "        sorted_idx = torch.cat([tensor(sorted(s, key=self.key, reverse=True)) for s in megabatches])\n",
    "        batches = [sorted_idx[i:i+self.bs] for i in range(0, len(sorted_idx), self.bs)]\n",
    "        max_idx = torch.argmax(tensor([self.key(ck[0]) for ck in batches]))\n",
    "        batches[0], batches[max_idx] = batches[max_idx], batches[0]\n",
    "        batch_idxs = torch.randperm(len(batches) - 2)\n",
    "        sorted_idx = torch.cat([batches[i+1] for i in batch_idxs]) if len(batches) > 1 else LongTensor([])\n",
    "        sorted_idx = torch.cat([batches[0], sorted_idx, batches[-1]])\n",
    "        return iter(sorted_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_collate(samples, pad_idx=1, pad_first=False):\n",
    "    max_len = max([len(s[0]) for s in samples])\n",
    "    res = torch.zeros(len(samples), max_len).long() + pad_idx\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first:\n",
    "            res[i, -len(s[0]):] = LongTensor(s[0])\n",
    "        else:\n",
    "            res[i, :len(s[0])] = LongTensor(s[0])\n",
    "    return res, tensor([s[1] for s in samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[23, 24]]), tensor([[45, 46, 47]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_collate([[[23, 24], [45, 46, 47]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "train_sampler = SortishSampler(ll.train.x, key = lambda t:len(ll.train[int(t)][0]), bs=bs)\n",
    "train_dl = DataLoader(ll.train, batch_size=bs, sampler = train_sampler, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_dl = iter(train_dl)\n",
    "x, y = next(iter_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3311])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([3311, 1576, 1486, 1481, 1425], 1022)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = []\n",
    "for i in range(x.size(0)):\n",
    "    lengths.append(x.size(1) - (x[i]==1).sum().item())\n",
    "lengths[:5], lengths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([415, 415, 415, 415, 415], 393)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter_dl)\n",
    "lengths = []\n",
    "for i in range(x.size(0)):\n",
    "    lengths.append(x.size(1) - (x[i]==1).sum().item())\n",
    "lengths[:5], lengths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     7,  1383,  ...,   154,     9,     3],\n",
       "        [    2,    18, 10054,  ...,    16,     9,     3],\n",
       "        [    2,     7,    68,  ...,    72,     9,     3],\n",
       "        ...,\n",
       "        [    2,    21,     7,  ...,     1,     1,     1],\n",
       "        [    2,     7,    19,  ...,     1,     1,     1],\n",
       "        [    2,    18,  1738,  ...,     1,     1,     1]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_clas_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    train_sampler = SortishSampler(train_ds.x, key=lambda t:len(train_ds.x[t]), bs=bs)\n",
    "    valid_sampler = SortSampler(valid_ds.x, key=lambda t:len(valid_ds.x[t]))\n",
    "    return (DataLoader(train_ds, batch_size=bs, sampler=train_sampler, collate_fn=pad_collate, **kwargs),\n",
    "           DataLoader(valid_ds, batch_size=bs*2, sampler=valid_sampler, collate_fn=pad_collate, **kwargs))\n",
    "\n",
    "def clas_databunchify(sd, bs, **kwargs):\n",
    "    return DataBunch(*get_clas_dls(sd.train, sd.valid, bs, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs, bptt = 64, 70\n",
    "data = clas_databunchify(ll, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converted 12_text.ipynb to nb_12.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 12_text.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_learnai_env)",
   "language": "python",
   "name": "conda_learnai_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
